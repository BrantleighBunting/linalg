{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encodings: Mathematical Derivations\n",
    "\n",
    "This notebook derives the mathematics behind positional encoding schemes used in transformers,\n",
    "explaining why they work and how to implement them."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Glossary of Terms\n\n| Term | Definition |\n|------|------------|\n| **Positional encoding** | Information added to token embeddings to indicate where each token is in the sequence. Without this, transformers can't distinguish word order. |\n| **Position** | An integer index (0, 1, 2, ...) indicating where a token appears in the sequence. Also called \"pos\" in formulas. |\n| **Sequence length (T)** | The number of tokens in a sequence. Positional encodings must handle sequences up to some maximum length $T_{max}$. |\n| **Model dimension (d)** | The size of token embeddings and hidden states, also called $d_{model}$. Each position gets a $d$-dimensional encoding. |\n| **Frequency/Wavelength** | In sinusoidal encodings, different dimensions oscillate at different frequencies. Low dimensions change fast (short wavelength), high dimensions change slowly (long wavelength). |\n| **Angular frequency ($\\omega$)** | $\\omega = 1/10000^{2i/d}$ — controls how fast each dimension pair oscillates with position. |\n| **Rotation matrix** | A matrix $R_\\theta$ that rotates 2D vectors by angle $\\theta$ while preserving their length. Used in RoPE. |\n| **Relative position** | The difference $(m - n)$ between two positions. RoPE encodes this directly; sinusoidal supports it via linear transforms. |\n| **Absolute position** | The actual index of a token (0, 1, 2, ...). Learned embeddings encode this directly. |\n| **Extrapolation** | Using the model on sequences longer than seen during training. Sinusoidal and RoPE support this; learned embeddings cannot. |\n| **Embedding matrix** | For learned positional embeddings, a matrix $W \\in \\mathbb{R}^{T_{max} \\times d}$ where row $i$ is the embedding for position $i$. |\n| **Permutation equivariance** | The property that reordering inputs just reorders outputs (same values, different positions). Attention is permutation equivariant without positional info. |\n| **RoPE (Rotary Position Embedding)** | A method that encodes position by rotating query and key vectors, making attention scores depend only on relative position. |\n| **NTK-aware scaling** | A technique to help RoPE extrapolate to longer sequences by adjusting rotation frequencies. |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulas and Theorems\n",
    "\n",
    "### Sinusoidal Positional Encoding (Vaswani et al., 2017)\n",
    "\n",
    "| Formula | Description |\n",
    "|---------|-------------|\n",
    "| $PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d}}\\right)$ | Even dimensions |\n",
    "| $PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d}}\\right)$ | Odd dimensions |\n",
    "| $\\omega_i = \\frac{1}{10000^{2i/d}}$ | Angular frequency for dimension pair $i$ |\n",
    "| $PE(pos + k) \\approx M_k \\cdot PE(pos)$ | Linear transformation property (relative positions) |\n",
    "\n",
    "### Rotary Position Embedding (RoPE) (Su et al., 2021)\n",
    "\n",
    "| Formula | Description |\n",
    "|---------|-------------|\n",
    "| $\\theta_i = 10000^{-2i/d}$ | Rotation frequency for dimension pair $i$ |\n",
    "| $R_\\theta = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}$ | 2D rotation matrix |\n",
    "| $(q'_0, q'_1) = (q_0\\cos(m\\theta) - q_1\\sin(m\\theta), q_0\\sin(m\\theta) + q_1\\cos(m\\theta))$ | Rotate query at position $m$ |\n",
    "| $q'_m \\cdot k'_n = f(q, k, m-n)$ | Dot product depends only on relative position |\n",
    "\n",
    "### Learned Positional Embeddings\n",
    "\n",
    "| Formula | Description |\n",
    "|---------|-------------|\n",
    "| $PE(pos) = W_{pos}$ | Direct lookup from embedding matrix $W \\in \\mathbb{R}^{T_{max} \\times d}$ |\n",
    "| $\\frac{\\partial L}{\\partial W_{pos}} = \\frac{\\partial L}{\\partial PE(pos)}$ | Gradient is upstream gradient |\n",
    "\n",
    "### Key Trigonometric Identities\n",
    "\n",
    "| Identity | Description |\n",
    "|----------|-------------|\n",
    "| $\\sin(a+b) = \\sin a \\cos b + \\cos a \\sin b$ | Sine addition |\n",
    "| $\\cos(a+b) = \\cos a \\cos b - \\sin a \\sin b$ | Cosine addition |\n",
    "| $\\cos a \\cos b + \\sin a \\sin b = \\cos(a - b)$ | Dot product of rotation vectors |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook assumes familiarity with:\n",
    "\n",
    "### 1. Trigonometric Functions\n",
    "\n",
    "The sine and cosine functions:\n",
    "- $\\sin(\\theta)$ and $\\cos(\\theta)$ are periodic with period $2\\pi$\n",
    "- $\\sin^2(\\theta) + \\cos^2(\\theta) = 1$\n",
    "- $\\sin(0) = 0$, $\\cos(0) = 1$\n",
    "- They form an orthonormal basis for representing periodic signals\n",
    "\n",
    "### 2. Rotation Matrices\n",
    "\n",
    "A 2D rotation by angle $\\theta$ is represented by:\n",
    "$$R_\\theta = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}$$\n",
    "\n",
    "Properties:\n",
    "- $R_\\theta R_\\phi = R_{\\theta + \\phi}$ (composition = addition of angles)\n",
    "- $R_\\theta^T = R_{-\\theta} = R_\\theta^{-1}$ (orthogonal matrix)\n",
    "- $\\det(R_\\theta) = 1$ (preserves lengths)\n",
    "\n",
    "### 3. Fourier Series Intuition\n",
    "\n",
    "Any periodic function can be represented as a sum of sines and cosines:\n",
    "$$f(x) = a_0 + \\sum_{n=1}^{\\infty} \\left(a_n \\cos(n\\omega x) + b_n \\sin(n\\omega x)\\right)$$\n",
    "\n",
    "Different frequencies capture different scales of variation:\n",
    "- Low frequencies: slow, global patterns\n",
    "- High frequencies: fast, local patterns\n",
    "\n",
    "### 4. Why Position Information Matters\n",
    "\n",
    "Attention is **permutation equivariant**: swapping input positions just swaps output positions.\n",
    "Without positional information, the model can't distinguish \"dog bites man\" from \"man bites dog\".\n",
    "\n",
    "We need to inject position information so the model knows where each token is in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Sinusoidal Positional Encoding\n",
    "\n",
    "### The Design\n",
    "\n",
    "The original transformer (Vaswani et al., 2017) uses fixed sinusoidal encodings:\n",
    "\n",
    "$$PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d}}\\right)$$\n",
    "$$PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d}}\\right)$$\n",
    "\n",
    "Where:\n",
    "- $pos$ is the position in the sequence (0, 1, 2, ...)\n",
    "- $i$ is the dimension index (0, 1, ..., d/2-1)\n",
    "- $d$ is the model dimension\n",
    "\n",
    "### Understanding the Frequencies\n",
    "\n",
    "Define the angular frequency for dimension pair $i$:\n",
    "$$\\omega_i = \\frac{1}{10000^{2i/d}}$$\n",
    "\n",
    "Then:\n",
    "$$PE_{(pos, 2i)} = \\sin(\\omega_i \\cdot pos)$$\n",
    "$$PE_{(pos, 2i+1)} = \\cos(\\omega_i \\cdot pos)$$\n",
    "\n",
    "The wavelengths (periods) range from $2\\pi$ (for $i=0$) to $2\\pi \\cdot 10000$ (for $i=d/2-1$).\n",
    "\n",
    "**Intuition**: Different dimension pairs encode position at different \"resolutions\":\n",
    "- Low $i$ (high frequency): Changes rapidly with position - distinguishes nearby positions\n",
    "- High $i$ (low frequency): Changes slowly - captures long-range structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_encoding(max_len, d_model):\n",
    "    \"\"\"Compute sinusoidal positional encodings.\n",
    "    \n",
    "    Args:\n",
    "        max_len: Maximum sequence length\n",
    "        d_model: Model dimension (must be even)\n",
    "    \n",
    "    Returns:\n",
    "        PE: Positional encoding matrix (max_len, d_model)\n",
    "    \"\"\"\n",
    "    pos = np.arange(max_len)[:, None]  # (T, 1)\n",
    "    i = np.arange(d_model // 2)[None, :]  # (1, d/2)\n",
    "    \n",
    "    # Compute frequencies: omega_i = 1 / 10000^(2i/d)\n",
    "    omega = 1.0 / (10000 ** (2 * i / d_model))  # (1, d/2)\n",
    "    \n",
    "    # Compute angles\n",
    "    angles = pos * omega  # (T, d/2) - broadcasting\n",
    "    \n",
    "    # Interleave sin and cos\n",
    "    PE = np.zeros((max_len, d_model))\n",
    "    PE[:, 0::2] = np.sin(angles)  # Even indices: sin\n",
    "    PE[:, 1::2] = np.cos(angles)  # Odd indices: cos\n",
    "    \n",
    "    return PE\n",
    "\n",
    "# Example\n",
    "T, d = 100, 64\n",
    "PE = sinusoidal_encoding(T, d)\n",
    "print(f\"Positional encoding shape: {PE.shape}\")\n",
    "print(f\"\\nFirst few positions, first 8 dims:\")\n",
    "print(PE[:5, :8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Full encoding heatmap\n",
    "im = axes[0, 0].imshow(PE.T, aspect='auto', cmap='RdBu', vmin=-1, vmax=1)\n",
    "axes[0, 0].set_xlabel('Position')\n",
    "axes[0, 0].set_ylabel('Dimension')\n",
    "axes[0, 0].set_title('Sinusoidal Positional Encoding')\n",
    "plt.colorbar(im, ax=axes[0, 0])\n",
    "\n",
    "# Individual dimensions\n",
    "positions = np.arange(T)\n",
    "for i, dim in enumerate([0, 1, 10, 11, 30, 31]):\n",
    "    axes[0, 1].plot(positions, PE[:, dim], label=f'dim {dim}', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Position')\n",
    "axes[0, 1].set_ylabel('Value')\n",
    "axes[0, 1].set_title('Individual Dimensions (different frequencies)')\n",
    "axes[0, 1].legend(fontsize=8)\n",
    "axes[0, 1].set_xlim(0, 50)\n",
    "\n",
    "# Wavelengths\n",
    "i_vals = np.arange(d // 2)\n",
    "wavelengths = 2 * np.pi * (10000 ** (2 * i_vals / d))\n",
    "axes[1, 0].semilogy(2 * i_vals, wavelengths)\n",
    "axes[1, 0].set_xlabel('Dimension index')\n",
    "axes[1, 0].set_ylabel('Wavelength')\n",
    "axes[1, 0].set_title('Wavelength per dimension pair (log scale)')\n",
    "axes[1, 0].axhline(y=2*np.pi, color='r', linestyle='--', alpha=0.5, label='2π')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Dot product similarity\n",
    "dots = PE @ PE.T  # (T, T)\n",
    "im = axes[1, 1].imshow(dots[:50, :50], cmap='RdBu')\n",
    "axes[1, 1].set_xlabel('Position j')\n",
    "axes[1, 1].set_ylabel('Position i')\n",
    "axes[1, 1].set_title('PE(i) · PE(j) - Position similarity')\n",
    "plt.colorbar(im, ax=axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Relative Position Property\n",
    "\n",
    "A key insight from the original paper: for any fixed offset $k$, there exists a linear transformation $M_k$ such that:\n",
    "\n",
    "$$PE(pos + k) = M_k \\cdot PE(pos)$$\n",
    "\n",
    "**Proof**: Consider a single dimension pair $(2i, 2i+1)$ with frequency $\\omega$:\n",
    "\n",
    "$$PE(pos) = \\begin{pmatrix} \\sin(\\omega \\cdot pos) \\\\ \\cos(\\omega \\cdot pos) \\end{pmatrix}$$\n",
    "\n",
    "$$PE(pos+k) = \\begin{pmatrix} \\sin(\\omega(pos+k)) \\\\ \\cos(\\omega(pos+k)) \\end{pmatrix}$$\n",
    "\n",
    "Using the angle addition formulas:\n",
    "$$\\sin(a+b) = \\sin a \\cos b + \\cos a \\sin b$$\n",
    "$$\\cos(a+b) = \\cos a \\cos b - \\sin a \\sin b$$\n",
    "\n",
    "We get:\n",
    "$$PE(pos+k) = \\begin{pmatrix} \\cos(\\omega k) & \\sin(\\omega k) \\\\ -\\sin(\\omega k) & \\cos(\\omega k) \\end{pmatrix} \\begin{pmatrix} \\sin(\\omega \\cdot pos) \\\\ \\cos(\\omega \\cdot pos) \\end{pmatrix}$$\n",
    "\n",
    "This is a rotation matrix! The full transformation $M_k$ is block-diagonal with these rotation blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_position_matrix(k, d_model):\n",
    "    \"\"\"Compute the linear transformation M_k such that PE(pos+k) = M_k @ PE(pos).\"\"\"\n",
    "    M = np.zeros((d_model, d_model))\n",
    "    for i in range(d_model // 2):\n",
    "        omega = 1.0 / (10000 ** (2 * i / d_model))\n",
    "        c, s = np.cos(omega * k), np.sin(omega * k)\n",
    "        # 2x2 rotation block for dimensions 2i, 2i+1\n",
    "        M[2*i, 2*i] = c\n",
    "        M[2*i, 2*i+1] = s\n",
    "        M[2*i+1, 2*i] = -s\n",
    "        M[2*i+1, 2*i+1] = c\n",
    "    return M\n",
    "\n",
    "# Verify the property\n",
    "pos = 10\n",
    "k = 5\n",
    "d = 32\n",
    "\n",
    "PE = sinusoidal_encoding(50, d)\n",
    "M_k = relative_position_matrix(k, d)\n",
    "\n",
    "# PE(pos+k) should equal M_k @ PE(pos)\n",
    "pe_direct = PE[pos + k]\n",
    "pe_transformed = M_k @ PE[pos]\n",
    "\n",
    "print(f\"PE(pos+k) directly:    {pe_direct[:8]}\")\n",
    "print(f\"M_k @ PE(pos):         {pe_transformed[:8]}\")\n",
    "print(f\"Max difference: {np.abs(pe_direct - pe_transformed).max():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Learned Positional Embeddings\n",
    "\n",
    "### The Simplest Approach\n",
    "\n",
    "Instead of using a fixed formula, we can learn position embeddings as parameters:\n",
    "\n",
    "$$PE(pos) = W_{pos,:}$$\n",
    "\n",
    "Where $W \\in \\mathbb{R}^{T_{max} \\times d}$ is a learnable embedding matrix.\n",
    "\n",
    "### Forward Pass\n",
    "\n",
    "Simply look up the row corresponding to each position:\n",
    "$$PE(pos) = W[pos]$$\n",
    "\n",
    "### Backward Pass\n",
    "\n",
    "The gradient flows directly to the corresponding row:\n",
    "$$\\frac{\\partial L}{\\partial W[pos]} = \\frac{\\partial L}{\\partial PE(pos)}$$\n",
    "\n",
    "If a position appears multiple times in a batch, gradients accumulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedPositionalEmbedding:\n",
    "    \"\"\"Learned positional embeddings with forward and backward passes.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_len, d_model, seed=42):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        # Initialize with small random values\n",
    "        self.W = rng.normal(0, 0.02, (max_len, d_model)).astype(np.float32)\n",
    "        self.gradW = np.zeros_like(self.W)\n",
    "        self._positions = None\n",
    "    \n",
    "    def forward(self, positions):\n",
    "        \"\"\"Look up embeddings for given positions.\n",
    "        \n",
    "        Args:\n",
    "            positions: Array of position indices\n",
    "        \n",
    "        Returns:\n",
    "            PE: Positional embeddings for each position\n",
    "        \"\"\"\n",
    "        self._positions = positions\n",
    "        return self.W[positions]\n",
    "    \n",
    "    def backward(self, dPE):\n",
    "        \"\"\"Accumulate gradients.\n",
    "        \n",
    "        Args:\n",
    "            dPE: Upstream gradient (same shape as forward output)\n",
    "        \"\"\"\n",
    "        # Each position accumulates its gradient\n",
    "        np.add.at(self.gradW, self._positions, dPE)\n",
    "    \n",
    "    def step(self, lr=0.01):\n",
    "        \"\"\"SGD update.\"\"\"\n",
    "        self.W -= lr * self.gradW\n",
    "        self.gradW.fill(0)\n",
    "\n",
    "# Demo\n",
    "max_len, d = 100, 16\n",
    "lpe = LearnedPositionalEmbedding(max_len, d)\n",
    "\n",
    "# Forward: get embeddings for positions 0, 1, 2, 3, 4\n",
    "positions = np.array([0, 1, 2, 3, 4])\n",
    "pe = lpe.forward(positions)\n",
    "print(f\"Embeddings shape: {pe.shape}\")\n",
    "print(f\"\\nLearned embeddings (first 8 dims):\")\n",
    "print(pe[:, :8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Learned vs Sinusoidal\n",
    "\n",
    "| Aspect | Sinusoidal | Learned |\n",
    "|--------|------------|----------|\n",
    "| Parameters | None | $T_{max} \\times d$ |\n",
    "| Extrapolation | Naturally extends to unseen lengths | Cannot extrapolate |\n",
    "| Relative positions | Built-in via linear transformation | Must be learned |\n",
    "| Flexibility | Fixed pattern | Can adapt to task |\n",
    "| Common usage | Original Transformer | GPT-2, BERT |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Rotary Position Embeddings (RoPE)\n",
    "\n",
    "RoPE (Su et al., 2021) takes a fundamentally different approach: instead of **adding** position information, it **rotates** the query and key vectors based on their position.\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "The attention score between query at position $m$ and key at position $n$ is:\n",
    "$$\\text{score} = q_m^T k_n$$\n",
    "\n",
    "If we rotate both $q$ and $k$ based on their positions:\n",
    "$$\\text{score} = (R_m q)^T (R_n k) = q^T R_m^T R_n k = q^T R_{n-m} k$$\n",
    "\n",
    "The score now depends only on the **relative position** $(n - m)$!\n",
    "\n",
    "### The Rotation\n",
    "\n",
    "For a 2D vector $(x_0, x_1)$ at position $m$ with rotation angle $\\theta$:\n",
    "\n",
    "$$\\begin{pmatrix} x'_0 \\\\ x'_1 \\end{pmatrix} = \\begin{pmatrix} \\cos(m\\theta) & -\\sin(m\\theta) \\\\ \\sin(m\\theta) & \\cos(m\\theta) \\end{pmatrix} \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix}$$\n",
    "\n",
    "Expanding:\n",
    "$$x'_0 = x_0 \\cos(m\\theta) - x_1 \\sin(m\\theta)$$\n",
    "$$x'_1 = x_0 \\sin(m\\theta) + x_1 \\cos(m\\theta)$$\n",
    "\n",
    "### Multi-dimensional Extension\n",
    "\n",
    "For a $d$-dimensional vector, we apply different rotations to each pair of dimensions:\n",
    "- Dimensions $(0, 1)$ rotate with frequency $\\theta_0$\n",
    "- Dimensions $(2, 3)$ rotate with frequency $\\theta_1$\n",
    "- ...\n",
    "- Dimensions $(d-2, d-1)$ rotate with frequency $\\theta_{d/2-1}$\n",
    "\n",
    "The frequencies follow the same pattern as sinusoidal:\n",
    "$$\\theta_i = 10000^{-2i/d}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbedding:\n",
    "    \"\"\"Rotary Position Embeddings (RoPE).\"\"\"\n",
    "    \n",
    "    def __init__(self, d_head, max_len=1024, base=10000.0):\n",
    "        assert d_head % 2 == 0, \"d_head must be even\"\n",
    "        self.d_head = d_head\n",
    "        self.base = base\n",
    "        \n",
    "        # Compute rotation frequencies: theta_i = base^(-2i/d)\n",
    "        i = np.arange(0, d_head, 2, dtype=np.float32)\n",
    "        self.inv_freq = 1.0 / (base ** (i / d_head))  # (d/2,)\n",
    "        \n",
    "        # Precompute sin/cos for all positions\n",
    "        pos = np.arange(max_len, dtype=np.float32)[:, None]  # (T, 1)\n",
    "        angles = pos * self.inv_freq[None, :]  # (T, d/2)\n",
    "        self.cos_cache = np.cos(angles)  # (T, d/2)\n",
    "        self.sin_cache = np.sin(angles)  # (T, d/2)\n",
    "    \n",
    "    def apply_rotation(self, x, cos, sin):\n",
    "        \"\"\"Apply rotation to x using precomputed cos/sin.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor (..., T, d)\n",
    "            cos: Cosine values (T, d/2)\n",
    "            sin: Sine values (T, d/2)\n",
    "        \n",
    "        Returns:\n",
    "            Rotated tensor, same shape as x\n",
    "        \"\"\"\n",
    "        # Split into even/odd pairs\n",
    "        x_even = x[..., 0::2]  # (..., T, d/2)\n",
    "        x_odd = x[..., 1::2]   # (..., T, d/2)\n",
    "        \n",
    "        # Apply 2D rotation to each pair\n",
    "        x_rot_even = x_even * cos - x_odd * sin\n",
    "        x_rot_odd = x_even * sin + x_odd * cos\n",
    "        \n",
    "        # Interleave back\n",
    "        x_rot = np.empty_like(x)\n",
    "        x_rot[..., 0::2] = x_rot_even\n",
    "        x_rot[..., 1::2] = x_rot_odd\n",
    "        \n",
    "        return x_rot\n",
    "    \n",
    "    def forward(self, q, k, offset=0):\n",
    "        \"\"\"Apply RoPE to query and key tensors.\n",
    "        \n",
    "        Args:\n",
    "            q: Query tensor (..., T, d)\n",
    "            k: Key tensor (..., T, d)\n",
    "            offset: Position offset (for KV-cache)\n",
    "        \n",
    "        Returns:\n",
    "            q_rot, k_rot: Rotated tensors\n",
    "        \"\"\"\n",
    "        T = q.shape[-2]\n",
    "        cos = self.cos_cache[offset:offset+T]  # (T, d/2)\n",
    "        sin = self.sin_cache[offset:offset+T]  # (T, d/2)\n",
    "        \n",
    "        q_rot = self.apply_rotation(q, cos, sin)\n",
    "        k_rot = self.apply_rotation(k, cos, sin)\n",
    "        \n",
    "        return q_rot, k_rot\n",
    "\n",
    "# Demo\n",
    "d_head = 8\n",
    "rope = RotaryPositionalEmbedding(d_head, max_len=100)\n",
    "\n",
    "# Create sample q, k at different positions\n",
    "T = 5\n",
    "q = np.random.randn(T, d_head)\n",
    "k = np.random.randn(T, d_head)\n",
    "\n",
    "q_rot, k_rot = rope.forward(q, k)\n",
    "\n",
    "print(f\"Original q[0]: {q[0]}\")\n",
    "print(f\"Rotated q[0]:  {q_rot[0]}\")\n",
    "print(f\"\\nNorm preserved: {np.linalg.norm(q[0]):.4f} -> {np.linalg.norm(q_rot[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proving the Relative Position Property\n",
    "\n",
    "Let's verify that $q_m^T k_n$ depends only on $(m - n)$.\n",
    "\n",
    "For a single dimension pair with frequency $\\theta$:\n",
    "\n",
    "$$q'_m = R(m\\theta) q, \\quad k'_n = R(n\\theta) k$$\n",
    "\n",
    "$$(q'_m)^T k'_n = q^T R(m\\theta)^T R(n\\theta) k = q^T R(-m\\theta) R(n\\theta) k = q^T R((n-m)\\theta) k$$\n",
    "\n",
    "The attention score is a function of $q$, $k$, and $(n-m)$ only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify relative position property\n",
    "d_head = 4\n",
    "rope = RotaryPositionalEmbedding(d_head, max_len=100)\n",
    "\n",
    "# Same q and k vectors\n",
    "q_vec = np.array([[1.0, 0.5, -0.3, 0.8]])\n",
    "k_vec = np.array([[0.2, -0.1, 0.7, 0.4]])\n",
    "\n",
    "# Test: score(q at pos 5, k at pos 3) should equal score(q at pos 10, k at pos 8)\n",
    "# Both have relative position = 2\n",
    "\n",
    "# Scenario 1: q at position 5, k at position 3\n",
    "q_at_5 = rope.apply_rotation(q_vec, rope.cos_cache[5:6], rope.sin_cache[5:6])\n",
    "k_at_3 = rope.apply_rotation(k_vec, rope.cos_cache[3:4], rope.sin_cache[3:4])\n",
    "score_1 = (q_at_5 @ k_at_3.T)[0, 0]\n",
    "\n",
    "# Scenario 2: q at position 10, k at position 8 (same relative position = 2)\n",
    "q_at_10 = rope.apply_rotation(q_vec, rope.cos_cache[10:11], rope.sin_cache[10:11])\n",
    "k_at_8 = rope.apply_rotation(k_vec, rope.cos_cache[8:9], rope.sin_cache[8:9])\n",
    "score_2 = (q_at_10 @ k_at_8.T)[0, 0]\n",
    "\n",
    "# Scenario 3: q at position 50, k at position 48 (same relative position = 2)\n",
    "q_at_50 = rope.apply_rotation(q_vec, rope.cos_cache[50:51], rope.sin_cache[50:51])\n",
    "k_at_48 = rope.apply_rotation(k_vec, rope.cos_cache[48:49], rope.sin_cache[48:49])\n",
    "score_3 = (q_at_50 @ k_at_48.T)[0, 0]\n",
    "\n",
    "print(\"Attention scores with same relative position (m - n = 2):\")\n",
    "print(f\"  q@5, k@3:   {score_1:.6f}\")\n",
    "print(f\"  q@10, k@8:  {score_2:.6f}\")\n",
    "print(f\"  q@50, k@48: {score_3:.6f}\")\n",
    "print(f\"\\nAll equal: {np.allclose([score_1, score_2, score_3], score_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing RoPE Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how a vector rotates with position\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "d_head = 64\n",
    "rope = RotaryPositionalEmbedding(d_head, max_len=100)\n",
    "\n",
    "# Same vector at different positions\n",
    "v = np.ones((1, d_head)) / np.sqrt(d_head)\n",
    "positions = [0, 5, 10, 20, 50]\n",
    "\n",
    "# Plot first two dimensions (fastest rotation)\n",
    "for pos in positions:\n",
    "    v_rot = rope.apply_rotation(v, rope.cos_cache[pos:pos+1], rope.sin_cache[pos:pos+1])\n",
    "    axes[0].scatter(v_rot[0, 0], v_rot[0, 1], s=100, label=f'pos={pos}')\n",
    "axes[0].set_xlabel('Dim 0')\n",
    "axes[0].set_ylabel('Dim 1')\n",
    "axes[0].set_title('Fast rotation (dims 0-1)')\n",
    "axes[0].legend()\n",
    "axes[0].axis('equal')\n",
    "\n",
    "# Plot middle dimensions (medium rotation)\n",
    "for pos in positions:\n",
    "    v_rot = rope.apply_rotation(v, rope.cos_cache[pos:pos+1], rope.sin_cache[pos:pos+1])\n",
    "    axes[1].scatter(v_rot[0, 30], v_rot[0, 31], s=100, label=f'pos={pos}')\n",
    "axes[1].set_xlabel('Dim 30')\n",
    "axes[1].set_ylabel('Dim 31')\n",
    "axes[1].set_title('Medium rotation (dims 30-31)')\n",
    "axes[1].legend()\n",
    "axes[1].axis('equal')\n",
    "\n",
    "# Plot last dimensions (slow rotation)\n",
    "for pos in positions:\n",
    "    v_rot = rope.apply_rotation(v, rope.cos_cache[pos:pos+1], rope.sin_cache[pos:pos+1])\n",
    "    axes[2].scatter(v_rot[0, 62], v_rot[0, 63], s=100, label=f'pos={pos}')\n",
    "axes[2].set_xlabel('Dim 62')\n",
    "axes[2].set_ylabel('Dim 63')\n",
    "axes[2].set_title('Slow rotation (dims 62-63)')\n",
    "axes[2].legend()\n",
    "axes[2].axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Comparison and Summary\n",
    "\n",
    "### Comparison Table\n",
    "\n",
    "| Feature | Sinusoidal | Learned | RoPE |\n",
    "|---------|------------|---------|------|\n",
    "| Parameters | 0 | $T_{max} \\times d$ | 0 |\n",
    "| Operation | Add to embeddings | Add to embeddings | Rotate Q, K |\n",
    "| Relative positions | Via linear transform | Implicit (learned) | Explicit (in dot product) |\n",
    "| Length extrapolation | Natural | Cannot | Good (with NTK-aware scaling) |\n",
    "| Used in | Original Transformer | GPT-2, BERT | LLaMA, Mistral, GPT-NeoX |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison: how position similarity decays with distance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "T, d = 100, 64\n",
    "\n",
    "# Sinusoidal\n",
    "PE_sin = sinusoidal_encoding(T, d)\n",
    "sim_sin = PE_sin @ PE_sin[0]  # Similarity of each position to position 0\n",
    "axes[0].plot(sim_sin)\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Similarity to position 0')\n",
    "axes[0].set_title('Sinusoidal: PE(pos) · PE(0)')\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Learned (random init)\n",
    "lpe = LearnedPositionalEmbedding(T, d)\n",
    "PE_learn = lpe.W\n",
    "sim_learn = PE_learn @ PE_learn[0]\n",
    "axes[1].plot(sim_learn)\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Similarity to position 0')\n",
    "axes[1].set_title('Learned (random init): PE(pos) · PE(0)')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# RoPE: show how attention score varies with relative position\n",
    "rope = RotaryPositionalEmbedding(d, max_len=T)\n",
    "q = np.random.randn(1, d)  # Fixed query vector\n",
    "k = np.random.randn(1, d)  # Fixed key vector\n",
    "\n",
    "scores = []\n",
    "for rel_pos in range(T):\n",
    "    q_rot = rope.apply_rotation(q, rope.cos_cache[rel_pos:rel_pos+1], rope.sin_cache[rel_pos:rel_pos+1])\n",
    "    k_rot = rope.apply_rotation(k, rope.cos_cache[0:1], rope.sin_cache[0:1])\n",
    "    scores.append((q_rot @ k_rot.T)[0, 0])\n",
    "\n",
    "axes[2].plot(scores)\n",
    "axes[2].set_xlabel('Relative position (m - n)')\n",
    "axes[2].set_ylabel('Attention score')\n",
    "axes[2].set_title('RoPE: q_m · k_0 (fixed q, k vectors)')\n",
    "axes[2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **Sinusoidal encodings** use different frequencies to encode position at multiple scales. They support relative positions through linear transformations.\n",
    "\n",
    "2. **Learned embeddings** are flexible but cannot extrapolate to unseen sequence lengths.\n",
    "\n",
    "3. **RoPE** encodes relative position directly in the attention score through rotation, leading to better length generalization.\n",
    "\n",
    "4. All methods aim to give the model information about **where** tokens are, but they do so in different ways:\n",
    "   - Sinusoidal/Learned: Add position information to token embeddings\n",
    "   - RoPE: Modify how Q and K interact based on positions\n",
    "\n",
    "5. The choice depends on your use case:\n",
    "   - Need fixed-length sequences? Learned works great (GPT-2, BERT)\n",
    "   - Need length generalization? RoPE is the modern choice (LLaMA, etc.)\n",
    "   - Want simplicity with no parameters? Sinusoidal is elegant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}